{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import mlflow\n",
    "import dagshub\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from mlflow.pyfunc import PythonModel\n",
    "import numpy as np\n",
    "\n",
    "from mlflow.genai import scorer\n",
    "from mlflow.genai.scorers import Correctness, Guidelines\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = ChatGroq(model=\"moonshotai/kimi-k2-instruct-0905\") #or llm=init_chat_model(groq:llama3-8b-8192)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as paruldiwakar\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as paruldiwakar\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"paruldiwakar/mlflow-genai\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"paruldiwakar/mlflow-genai\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository paruldiwakar/mlflow-genai initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository paruldiwakar/mlflow-genai initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dagshub.init(repo_owner='paruldiwakar',\n",
    "             repo_name='mlflow-genai',\n",
    "             mlflow=True)\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/paruldiwakar/mlflow-genai.mlflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame(\n",
    "    {\n",
    "        \"inputs\": [\n",
    "            \"What is MLflow?\",\n",
    "            \"What is Spark?\",\n",
    "        ],\n",
    "        \"ground_truth\": [\n",
    "            \"MLflow is an open-source platform for managing the end-to-end machine learning (ML) \"\n",
    "            \"lifecycle. It was developed by Databricks, a company that specializes in big data and \"\n",
    "            \"machine learning solutions. MLflow is designed to address the challenges that data \"\n",
    "            \"scientists and machine learning engineers face when developing, training, and deploying \"\n",
    "            \"machine learning models.\",\n",
    "            \"Apache Spark is an open-source, distributed computing system designed for big data \"\n",
    "            \"processing and analytics. It was developed in response to limitations of the Hadoop \"\n",
    "            \"MapReduce computing model, offering improvements in speed and ease of use. Spark \"\n",
    "            \"provides libraries for various tasks such as data ingestion, processing, and analysis \"\n",
    "            \"through its components like Spark SQL for structured data, Spark Streaming for \"\n",
    "            \"real-time data processing, and MLlib for machine learning tasks\",\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is MLflow?</td>\n",
       "      <td>MLflow is an open-source platform for managing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is Spark?</td>\n",
       "      <td>Apache Spark is an open-source, distributed co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            inputs                                       ground_truth\n",
       "0  What is MLflow?  MLflow is an open-source platform for managing...\n",
       "1   What is Spark?  Apache Spark is an open-source, distributed co..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalution Metric Functions\n",
    "(i dont want to buy the open ai token lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "def rouge_l(eval_df, _):\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "    scores = [\n",
    "        scorer.score(gt, pred)[\"rougeL\"].fmeasure\n",
    "        for gt, pred in zip(eval_df[\"ground_truth\"], eval_df[\"prediction\"])\n",
    "    ]\n",
    "    return float(np.mean(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@scorer\n",
    "def is_concise(outputs: str) -> bool:\n",
    "    \"\"\"Evaluate if the answer is concise (less than 5 words)\"\"\"\n",
    "    return len(outputs.split()) <= 5\n",
    "\n",
    "\n",
    "scorers = [\n",
    "    Correctness(),\n",
    "    Guidelines(name=\"is_english\", guidelines=\"The answer must be in English\"),\n",
    "    is_concise,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI learns patterns from data to make smart decisions or predictions.\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "# The client gets the API key from the environment variable `GEMINI_API_KEY`.\n",
    "client = genai.Client()\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\", contents=\"Explain how AI works in a few words\"\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/c5b37244483849fa8ad2ef9bd266b78c', creation_time=1767117540978, experiment_id='2', last_update_time=1767117540978, lifecycle_stage='active', name='LLM Evaluation', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"LLM Evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/31 01:25:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/31 01:25:57 INFO mlflow.pyfunc: Inferring model signature from input example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run fortunate-bird-751 at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/0/runs/6bcf6fc5fb5a4d30ab334d826ffacbed\n",
      "üß™ View experiment at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/0\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Failed to serialize Python model. Please save the model into a python file and use code-based logging method instead. Seehttps://mlflow.org/docs/latest/models.html#models-from-code for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py:1094\u001b[39m, in \u001b[36m_save_model_with_class_artifacts_params\u001b[39m\u001b[34m(path, python_model, signature, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\u001b[39m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     \u001b[43m_maybe_compress_cloudpickle_dump\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_python_model_subpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py:834\u001b[39m, in \u001b[36m_maybe_compress_cloudpickle_dump\u001b[39m\u001b[34m(python_model, path, compression)\u001b[39m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m file_open(path, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     \u001b[43mcloudpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py:1526\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol, buffer_callback)\u001b[39m\n\u001b[32m   1514\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Serialize obj as bytes streamed into file\u001b[39;00m\n\u001b[32m   1515\u001b[39m \n\u001b[32m   1516\u001b[39m \u001b[33;03mprotocol defaults to cloudpickle.DEFAULT_PROTOCOL which is an alias to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1524\u001b[39m \u001b[33;03mnext).\u001b[39;00m\n\u001b[32m   1525\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m \u001b[43mPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py:1313\u001b[39m, in \u001b[36mPickler.dump\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mTypeError\u001b[39m: cannot pickle '_thread.RLock' object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run() \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Wrap llm as an MLflow model.\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     logged_model_info =  \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGroqQAWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is agentic AI?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     model_uri = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.info.run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m     \u001b[38;5;66;03m# Use predefined question-answering metrics to evaluate our model.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/tracing/provider.py:633\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    632\u001b[39m     is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    635\u001b[39m     enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3600\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(artifact_path, loader_module, data_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, prompts, name, params, tags, model_type, step, model_id)\u001b[39m\n\u001b[32m   3400\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3401\u001b[39m \u001b[33;03mLog a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[32m   3402\u001b[39m \u001b[33;03martifact for the current run.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3597\u001b[39m \u001b[33;03m    metadata of the logged model.\u001b[39;00m\n\u001b[32m   3598\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3599\u001b[39m flavor_name = _get_pyfunc_model_flavor_name(python_model)\n\u001b[32m-> \u001b[39m\u001b[32m3600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3601\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3608\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3611\u001b[39m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3612\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3621\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3628\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only used for checking python model type\u001b[39;49;00m\n\u001b[32m   3629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3630\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/models/model.py:1209\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[39m\n\u001b[32m   1197\u001b[39m     prompts = [pr.uri \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pr, PromptVersion) \u001b[38;5;28;01melse\u001b[39;00m pr \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m   1199\u001b[39m mlflow_model = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m   1200\u001b[39m     artifact_path=model.artifact_location,\n\u001b[32m   1201\u001b[39m     model_uuid=model.model_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1207\u001b[39m     model_id=model.model_id,\n\u001b[32m   1208\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m \u001b[43mflavor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result\u001b[39;00m\n\u001b[32m   1211\u001b[39m \u001b[38;5;66;03m# in __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path).rglob(\u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/tracing/provider.py:638\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    636\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    637\u001b[39m         is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m         result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[38;5;66;03m# and let other exceptions propagate.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowTracingException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3341\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(path, loader_module, data_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, **kwargs)\u001b[39m\n\u001b[32m   3327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _save_model_with_loader_module_and_data_path(\n\u001b[32m   3328\u001b[39m         path=path,\n\u001b[32m   3329\u001b[39m         loader_module=loader_module,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3338\u001b[39m         infer_code_paths=infer_code_paths,\n\u001b[32m   3339\u001b[39m     )\n\u001b[32m   3340\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m second_argument_set_specified:\n\u001b[32m-> \u001b[39m\u001b[32m3341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_save_model_with_class_artifacts_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3343\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3345\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_code_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_code_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3354\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py:1098\u001b[39m, in \u001b[36m_save_model_with_class_artifacts_params\u001b[39m\u001b[34m(path, python_model, signature, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\u001b[39m\n\u001b[32m   1094\u001b[39m         _maybe_compress_cloudpickle_dump(\n\u001b[32m   1095\u001b[39m             python_model, os.path.join(path, saved_python_model_subpath), compression\n\u001b[32m   1096\u001b[39m         )\n\u001b[32m   1097\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1098\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   1099\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFailed to serialize Python model. Please save the model into a python file \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1100\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mand use code-based logging method instead. See\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhttps://mlflow.org/docs/latest/models.html#models-from-code for more information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1104\u001b[39m     custom_model_config_kwargs[CONFIG_KEY_PYTHON_MODEL] = saved_python_model_subpath\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artifacts:\n",
      "\u001b[31mMlflowException\u001b[39m: Failed to serialize Python model. Please save the model into a python file and use code-based logging method instead. Seehttps://mlflow.org/docs/latest/models.html#models-from-code for more information."
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    # Wrap llm as an MLflow model.\n",
    "    logged_model_info =  mlflow.pyfunc.log_model(\n",
    "        artifact_path=\"model\",\n",
    "        python_model=GroqQAWrapper(),\n",
    "        input_example=pd.DataFrame({\"question\": [\"What is agentic AI?\"]})\n",
    "    )\n",
    "\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\"\n",
    "\n",
    "    # Use predefined question-answering metrics to evaluate our model.\n",
    "    results = mlflow.evaluate(\n",
    "        model_uri,\n",
    "        eval_data,  # DataFrame with 'question' and 'ground_truth'\n",
    "        targets=\"ground_truth\",\n",
    "        model_type=\"question-answering\",\n",
    "        extra_metrics=[\n",
    "            Correctness(model=\"gemini/gemini-2.5-flash\"),\n",
    "            mlflow.metrics.toxicity(model=\"gemini/gemini-2.5-flash\"),\n",
    "            mlflow.metrics.genai.answer_similarity(model=\"gemini/gemini-2.5-flash\"),\n",
    "            mlflow.metrics.latency()\n",
    "        ],\n",
    "    )\n",
    "    print(f\"See aggregated evaluation results below: \\n{results.metrics}\")\n",
    "\n",
    "    eval_table = results.tables[\"eval_results_table\"]\n",
    "    df = pd.DataFrame(eval_table)\n",
    "    df.to_csv(\"eval.csv\", index=False)\n",
    "\n",
    "    print(\"Aggregated metrics:\")\n",
    "    print(eval_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.chains.llm import LLMChain\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# groq_model.py\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchains\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mllm\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LLMChain\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;43;01mclass\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43;01mGroqWrapper\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPythonModel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[38;5;250;43m \u001b[39;49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# llm and prompt can be None here; they will be set at predict time\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py:202\u001b[39m, in \u001b[36mPythonModel.__init_subclass__\u001b[39m\u001b[34m(cls, **kwargs)\u001b[39m\n\u001b[32m    200\u001b[39m predict_attr = \u001b[38;5;28mcls\u001b[39m.\u001b[34m__dict__\u001b[39m.get(\u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m predict_attr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(predict_attr):\n\u001b[32m--> \u001b[39m\u001b[32m202\u001b[39m     func_info = \u001b[43m_get_func_info_if_type_hint_supported\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredict_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    203\u001b[39m     \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpredict\u001b[39m\u001b[33m\"\u001b[39m, _wrap_predict_with_pyfunc(predict_attr, func_info))\n\u001b[32m    204\u001b[39m predict_stream_attr = \u001b[38;5;28mcls\u001b[39m.\u001b[34m__dict__\u001b[39m.get(\u001b[33m\"\u001b[39m\u001b[33mpredict_stream\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/utils/annotations.py:303\u001b[39m, in \u001b[36mfilter_user_warnings_once.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m    302\u001b[39m     warnings.simplefilter(\u001b[33m\"\u001b[39m\u001b[33monce\u001b[39m\u001b[33m\"\u001b[39m, category=\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:158\u001b[39m, in \u001b[36m_get_func_info_if_type_hint_supported\u001b[39m\u001b[34m(func)\u001b[39m\n\u001b[32m    156\u001b[39m input_arg_index = \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_context_in_predict_function_signature(func=func) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    157\u001b[39m type_hint = _extract_type_hints(func, input_arg_index=input_arg_index).input\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m input_param_name = \u001b[43mparam_names\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_arg_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m type_hint \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _signature_cannot_be_inferred_from_type_hint(type_hint) \u001b[38;5;129;01mor\u001b[39;00m _is_type_hint_from_example(\n\u001b[32m    161\u001b[39m         type_hint\n\u001b[32m    162\u001b[39m     ):\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# groq_model.py\n",
    "from langchain.chains.llm import LLMChain\n",
    "\n",
    "class GroqWrapper:\n",
    "    def __init__(self, llm, prompt):\n",
    "        self.chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "    def predict(self, context):\n",
    "        # context is a pandas DataFrame\n",
    "        questions = context[\"inputs\"].tolist()\n",
    "        return [self.chain.run({\"question\": q}) for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paruldiwakar/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    }
   ],
   "source": [
    "class GroqQAWrapper(mlflow.pyfunc.PythonModel):\n",
    "    def load_context(self, context):\n",
    "        system_prompt = \"Answer the following question in two sentences\"\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", \"{question}\")\n",
    "        ])\n",
    "\n",
    "        llm = ChatGroq(\n",
    "            model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "            temperature=0\n",
    "        )\n",
    "\n",
    "        self.chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        # MLflow GenAI evaluator passes everything as `inputs`\n",
    "        if \"inputs\" in model_input.columns:\n",
    "            questions = model_input[\"inputs\"]\n",
    "        elif \"question\" in model_input.columns:\n",
    "            questions = model_input[\"question\"]\n",
    "        elif \"prompt\" in model_input.columns:\n",
    "            questions = model_input[\"prompt\"]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"No valid input column found. Columns: {model_input.columns}\"\n",
    "            )\n",
    "\n",
    "        return questions.apply(\n",
    "            lambda q: self.chain.invoke({\"question\": q})\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = pd.DataFrame({\n",
    "    \"inputs\": [{\"question\": \"What is MLflow?\"}],\n",
    "    \"ground_truth\": [\n",
    "        \"MLflow is an open-source platform for managing the end-to-end ML lifecycle...\"\n",
    "    ],\n",
    "    \"expected_response\": [\n",
    "        \"MLflow is an open-source platform for managing the end-to-end ML lifecycle...\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello there!\n"
     ]
    }
   ],
   "source": [
    "import litellm\n",
    "\n",
    "resp = litellm.completion(\n",
    "    model=\"gemini/gemini-2.5-flash\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Say hello in one sentence\"}],\n",
    ")\n",
    "\n",
    "print(resp.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paruldiwakar/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run crawling-slug-532 at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/2/runs/1ad56a305b4c459dbe6bf5a829b18b35\n",
      "üß™ View experiment at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/2\n",
      "models:/m-7831511d626b42c89ae98184fa736321\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "model_path = \"groq_model.py\"\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.pyfunc.log_model(\n",
    "        python_model=model_path,   # path to file\n",
    "        name=\"groq_qa_model\",\n",
    "    )\n",
    "\n",
    "print(model_info.model_uri)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  4.39it/s]\n",
      "/Users/paruldiwakar/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MLflow is an open-source platform that manages the end-to-end machine-learning lifecycle, including experiment tracking, model packaging, and deployment. It provides standardized APIs and a unified UI so teams can reproduce runs, share models, and push them to production regardless of the library or cloud they use.']\n"
     ]
    }
   ],
   "source": [
    "import mlflow.pyfunc\n",
    "import pandas as pd\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    \"inputs\": [\"What is MLflow?\"]\n",
    "})\n",
    "\n",
    "print(model.predict(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn_wrapped(**kwargs):\n",
    "    key = list(kwargs.keys())[0]\n",
    "    value = kwargs[key]\n",
    "    return model.predict(pd.DataFrame({\"inputs\": [value]}))[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/31 03:43:43 INFO mlflow.genai.scorers.validation: The input data is missing following columns that are required by the specified scorers. The results will be null for those scorers.\n",
      " - `expected_response or expected_facts` field in `expectations` column is required by [correctness].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/31 03:43:43 INFO mlflow.genai.utils.data_validation: Testing model prediction with the first sample in the dataset. To disable this check, set the MLFLOW_GENAI_EVAL_SKIP_TRACE_VALIDATION environment variable to True.\n",
      "2025/12/31 03:43:43 WARNING mlflow.tracing.fluent: Failed to start span RunnableSequence: 'NonRecordingSpan' object has no attribute 'context'. For full traceback, set logging level to debug.\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [Elapsed: 00:06, Remaining: 00:00] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<!DOCTYPE html>\n",
       "<html lang=\"en\">\n",
       "<head>\n",
       "    <title>Evaluation output</title>\n",
       "    <meta charset=\"UTF-8\">\n",
       "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
       "    <style>\n",
       "        body {\n",
       "            font-family: Arial, sans-serif;\n",
       "        }\n",
       "\n",
       "        .header {\n",
       "            a.button {\n",
       "                padding: 4px 8px;\n",
       "                line-height: 20px;\n",
       "                box-shadow: none;\n",
       "                height: 20px;\n",
       "                display: inline-flex;\n",
       "                align-items: center;\n",
       "                justify-content: center;\n",
       "                vertical-align: middle;\n",
       "                background-color: rgb(34, 114, 180);\n",
       "                color: rgb(255, 255, 255);\n",
       "                text-decoration: none;\n",
       "                animation-duration: 0s;\n",
       "                transition: none 0s ease 0s;\n",
       "                position: relative;\n",
       "                white-space: nowrap;\n",
       "                text-align: center;\n",
       "                border: 1px solid rgb(192, 205, 216);\n",
       "                cursor: pointer;\n",
       "                user-select: none;\n",
       "                touch-action: manipulation;\n",
       "                border-radius: 4px;\n",
       "                gap: 6px;\n",
       "            }\n",
       "\n",
       "            a.button:hover {\n",
       "                background-color: rgb(14, 83, 139) !important;\n",
       "                border-color: transparent !important;\n",
       "                color: rgb(255, 255, 255) !important;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .warnings-section {\n",
       "            margin-top: 8px;\n",
       "\n",
       "            ul {\n",
       "                list-style-type: none;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        .instructions-section {\n",
       "            margin-top: 16px;\n",
       "            font-size: 14px;\n",
       "\n",
       "            ul {\n",
       "                margin-top: 0;\n",
       "                margin-bottom: 0;\n",
       "            }\n",
       "        }\n",
       "\n",
       "        code {\n",
       "            font-family: monospace;\n",
       "        }\n",
       "\n",
       "        .note {\n",
       "            color: #666;\n",
       "        }\n",
       "\n",
       "        a {\n",
       "            color: #2272B4;\n",
       "            text-decoration: none;\n",
       "        }\n",
       "\n",
       "        a:hover {\n",
       "            color: #005580;\n",
       "        }\n",
       "    </style>\n",
       "</head>\n",
       "<body>\n",
       "<div>\n",
       "    <div class=\"header\">\n",
       "        <a href=\"https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/2/evaluation-runs?selectedRunUuid=4dbf624bba96463dba25acb00ac3f607\" class=\"button\">\n",
       "            View evaluation results in MLflow\n",
       "            <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1em\" height=\"1em\" fill=\"none\" viewBox=\"0 0 16 16\" aria-hidden=\"true\" focusable=\"false\" class=\"\">\n",
       "                <path fill=\"currentColor\" d=\"M10 1h5v5h-1.5V3.56L8.53 8.53 7.47 7.47l4.97-4.97H10z\"></path>\n",
       "                <path fill=\"currentColor\" d=\"M1 2.75A.75.75 0 0 1 1.75 2H8v1.5H2.5v10h10V8H14v6.25a.75.75 0 0 1-.75.75H1.75a.75.75 0 0 1-.75-.75z\"></path>\n",
       "            </svg>\n",
       "        </a>\n",
       "    </div>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mlflow.genai import scorer\n",
    "from mlflow.genai.scorers import Correctness, Guidelines\n",
    "\n",
    "@scorer\n",
    "def is_concise(outputs: str) -> bool:\n",
    "    return len(outputs.split()) <= 40\n",
    "\n",
    "scorers = [\n",
    "    Correctness(),\n",
    "    Guidelines(name=\"is_english\", guidelines=\"The answer must be in English\"),\n",
    "    is_concise,\n",
    "]\n",
    "\n",
    "results = mlflow.genai.evaluate(\n",
    "    data=eval_data,\n",
    "    predict_fn=predict_fn_wrapped,\n",
    "    scorers=scorers,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace_id</th>\n",
       "      <th>correctness/value</th>\n",
       "      <th>is_english/value</th>\n",
       "      <th>is_concise/value</th>\n",
       "      <th>trace</th>\n",
       "      <th>client_request_id</th>\n",
       "      <th>state</th>\n",
       "      <th>request_time</th>\n",
       "      <th>execution_duration</th>\n",
       "      <th>request</th>\n",
       "      <th>response</th>\n",
       "      <th>trace_metadata</th>\n",
       "      <th>tags</th>\n",
       "      <th>spans</th>\n",
       "      <th>assessments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tr-a7a8d380b5a00500d206cd8be80dd5cd</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>{\"info\": {\"trace_id\": \"tr-a7a8d380b5a00500d206...</td>\n",
       "      <td>None</td>\n",
       "      <td>OK</td>\n",
       "      <td>1767132826475</td>\n",
       "      <td>3691</td>\n",
       "      <td>{'question': 'What is MLflow?'}</td>\n",
       "      <td>MLflow is an open-source platform that manages...</td>\n",
       "      <td>{'mlflow.sourceRun': '4dbf624bba96463dba25acb0...</td>\n",
       "      <td>{'mlflow.artifactLocation': 'mlflow-artifacts:...</td>\n",
       "      <td>[{'trace_id': 'p6jTgLWgBQDSBs2L6A3VzQ==', 'spa...</td>\n",
       "      <td>[{'assessment_id': 'a-d69b04f53a6240bdb2970343...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              trace_id correctness/value is_english/value  \\\n",
       "0  tr-a7a8d380b5a00500d206cd8be80dd5cd              None             None   \n",
       "\n",
       "   is_concise/value                                              trace  \\\n",
       "0             False  {\"info\": {\"trace_id\": \"tr-a7a8d380b5a00500d206...   \n",
       "\n",
       "  client_request_id state   request_time  execution_duration  \\\n",
       "0              None    OK  1767132826475                3691   \n",
       "\n",
       "                           request  \\\n",
       "0  {'question': 'What is MLflow?'}   \n",
       "\n",
       "                                            response  \\\n",
       "0  MLflow is an open-source platform that manages...   \n",
       "\n",
       "                                      trace_metadata  \\\n",
       "0  {'mlflow.sourceRun': '4dbf624bba96463dba25acb0...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  {'mlflow.artifactLocation': 'mlflow-artifacts:...   \n",
       "\n",
       "                                               spans  \\\n",
       "0  [{'trace_id': 'p6jTgLWgBQDSBs2L6A3VzQ==', 'spa...   \n",
       "\n",
       "                                         assessments  \n",
       "0  [{'assessment_id': 'a-d69b04f53a6240bdb2970343...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tables['eval_results']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.genai.evaluation.entities.EvaluationResult"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.models.evaluation import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/paruldiwakar/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/models/evaluation/deprecated.py:9: FutureWarning: The `mlflow.evaluate` API has been deprecated as of MLflow 3.0.0. Please use these new alternatives:\n",
      "\n",
      " - For traditional ML or deep learning models: Use `mlflow.models.evaluate`, which maintains full compatibility with the original `mlflow.evaluate` API.\n",
      "\n",
      " - For LLMs or GenAI applications: Use the new `mlflow.genai.evaluate` API, which offers enhanced features specifically designed for evaluating LLMs and GenAI applications.\n",
      "\n",
      "  warnings.warn(\n",
      "Downloading artifacts: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  2.55it/s]\n",
      "/Users/paruldiwakar/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/utils/data_validation.py:186: UserWarning: \u001b[33mAdd type hints to the `predict` method to enable data validation and automatic signature inference during model logging. Check https://mlflow.org/docs/latest/model/python_model.html#type-hint-usage-in-pythonmodel for more details.\u001b[0m\n",
      "  color_warning(\n",
      "2025/12/31 03:43:04 INFO mlflow.tracking.fluent: Active model is set to the logged model with ID: m-7831511d626b42c89ae98184fa736321\n",
      "2025/12/31 03:43:04 INFO mlflow.tracking.fluent: Use `mlflow.set_active_model` to set the active model to a different one if needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run illustrious-bat-673 at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/2/runs/a0697c53fe8f45e1adfd450993218b4d\n",
      "üß™ View experiment at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/2\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "In the 'extra_metrics' parameter, the following metrics have the wrong type:\n- Metric 'name='correctness' aggregations=None description=\"Check whether the expected facts (from expected_response or expected_facts) are supported by the model's response.\" required_columns={'inputs', 'outputs'} model='gemini/gemini-2.5-flash'' has type 'Correctness'\nPlease ensure that all extra metrics are instances of mlflow.metrics.EvaluationMetric.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[87]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m answer_similarity\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m results = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_uri\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m                       \u001b[49m\u001b[38;5;66;43;03m# your DataFrame\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mground_truth\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion-answering\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mCorrectness\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini/gemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#answer_similarity(model=\"gemini/gemini-2.5-flash\"),\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(results.metrics)\n\u001b[32m     15\u001b[39m results.tables[\u001b[33m\"\u001b[39m\u001b[33meval_results_table\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/models/evaluation/deprecated.py:19\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(model_evaluate)\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(*args, **kwargs):\n\u001b[32m      9\u001b[39m     warnings.warn(\n\u001b[32m     10\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `mlflow.evaluate` API has been deprecated as of MLflow 3.0.0. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease use these new alternatives:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m     17\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m     18\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/models/evaluation/base.py:1791\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(model, data, model_type, targets, predictions, dataset_path, feature_names, evaluators, evaluator_config, extra_metrics, custom_artifacts, env_manager, model_config, inference_params, model_id, _called_from_genai_evaluate)\u001b[39m\n\u001b[32m   1788\u001b[39m predictions_expected_in_model_output = predictions \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1790\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1791\u001b[39m     evaluate_result = \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator_name_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_name_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluator_name_to_conf_map\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluator_name_to_conf_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_artifacts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_artifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredictions_expected_in_model_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1803\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1804\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1805\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, _ServedPyFuncModel):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/telemetry/track.py:30\u001b[39m, in \u001b[36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m start_time = time.time()\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result  \u001b[38;5;66;03m# noqa: RET504\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/models/evaluation/base.py:1032\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(model, model_type, model_id, dataset, run_id, evaluator_name_list, evaluator_name_to_conf_map, extra_metrics, custom_artifacts, predictions, evaluators)\u001b[39m\n\u001b[32m   1030\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m eval_.evaluator.can_evaluate(model_type=model_type, evaluator_config=eval_.config):\n\u001b[32m   1031\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m configure_autologging_for_evaluation(enable_tracing=should_enable_tracing):\n\u001b[32m-> \u001b[39m\u001b[32m1032\u001b[39m         eval_result = \u001b[43meval_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1037\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1038\u001b[39m \u001b[43m            \u001b[49m\u001b[43mevaluator_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1039\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcustom_artifacts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_artifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m eval_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1045\u001b[39m         eval_results.append(eval_result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/models/evaluation/default_evaluator.py:928\u001b[39m, in \u001b[36mBuiltInEvaluator.evaluate\u001b[39m\u001b[34m(self, model_type, dataset, run_id, evaluator_config, model, extra_metrics, custom_artifacts, predictions, model_id, **kwargs)\u001b[39m\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bad_metrics) > \u001b[32m0\u001b[39m:\n\u001b[32m    925\u001b[39m     message = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    926\u001b[39m         [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m- Metric \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has type \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m bad_metrics]\n\u001b[32m    927\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m    929\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIn the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mextra_metrics\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter, the following metrics have the wrong type:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    930\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmessage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    931\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease ensure that all extra metrics are instances of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    932\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmlflow.metrics.EvaluationMetric.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    933\u001b[39m     )\n\u001b[32m    935\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\n\u001b[32m    937\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m TempDir() \u001b[38;5;28;01mas\u001b[39;00m temp_dir, matplotlib.rc_context(_matplotlib_config):\n",
      "\u001b[31mMlflowException\u001b[39m: In the 'extra_metrics' parameter, the following metrics have the wrong type:\n- Metric 'name='correctness' aggregations=None description=\"Check whether the expected facts (from expected_response or expected_facts) are supported by the model's response.\" required_columns={'inputs', 'outputs'} model='gemini/gemini-2.5-flash'' has type 'Correctness'\nPlease ensure that all extra metrics are instances of mlflow.metrics.EvaluationMetric."
     ]
    }
   ],
   "source": [
    "from mlflow.metrics.genai import answer_similarity\n",
    "\n",
    "results = mlflow.evaluate(\n",
    "    model_info.model_uri,\n",
    "    eval_data,                       # your DataFrame\n",
    "    targets=\"ground_truth\",\n",
    "    model_type=\"question-answering\",\n",
    "    extra_metrics=[\n",
    "        Correctness(model=\"gemini/gemini-2.5-flash\"),\n",
    "        #answer_similarity(model=\"gemini/gemini-2.5-flash\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(results.metrics)\n",
    "results.tables[\"eval_results_table\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/31 02:09:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/31 02:09:14 INFO mlflow.pyfunc: Inferring model signature from input example\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run youthful-ant-658 at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/0/runs/416ad26576c34774b928e8a63c8e0f54\n",
      "üß™ View experiment at: https://dagshub.com/paruldiwakar/mlflow-genai.mlflow/#/experiments/0\n"
     ]
    },
    {
     "ename": "MlflowException",
     "evalue": "Failed to serialize Python model. Please save the model into a python file and use code-based logging method instead. Seehttps://mlflow.org/docs/latest/models.html#models-from-code for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py:1094\u001b[39m, in \u001b[36m_save_model_with_class_artifacts_params\u001b[39m\u001b[34m(path, python_model, signature, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\u001b[39m\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     \u001b[43m_maybe_compress_cloudpickle_dump\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msaved_python_model_subpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py:834\u001b[39m, in \u001b[36m_maybe_compress_cloudpickle_dump\u001b[39m\u001b[34m(python_model, path, compression)\u001b[39m\n\u001b[32m    833\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m file_open(path, \u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m out:\n\u001b[32m--> \u001b[39m\u001b[32m834\u001b[39m     \u001b[43mcloudpickle\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py:1526\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, file, protocol, buffer_callback)\u001b[39m\n\u001b[32m   1514\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Serialize obj as bytes streamed into file\u001b[39;00m\n\u001b[32m   1515\u001b[39m \n\u001b[32m   1516\u001b[39m \u001b[33;03mprotocol defaults to cloudpickle.DEFAULT_PROTOCOL which is an alias to\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1524\u001b[39m \u001b[33;03mnext).\u001b[39;00m\n\u001b[32m   1525\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1526\u001b[39m \u001b[43mPickler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuffer_callback\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/cloudpickle/cloudpickle.py:1313\u001b[39m, in \u001b[36mPickler.dump\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m   1312\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1313\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRecursionError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mTypeError\u001b[39m: cannot pickle '_thread.RLock' object",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMlflowException\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m mlflow.start_run() \u001b[38;5;28;01mas\u001b[39;00m run: \u001b[38;5;66;03m# Wrap llm as an MLflow model. \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     logged_model_info = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGroqQAWrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquestion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWhat is agentic AI?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     model_uri = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mruns:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrun.info.run_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/model\u001b[39m\u001b[33m\"\u001b[39m \n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# Use predefined question-answering metrics to evaluate our model. \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/tracing/provider.py:633\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    632\u001b[39m     is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m633\u001b[39m     result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    634\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    635\u001b[39m     enable()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3600\u001b[39m, in \u001b[36mlog_model\u001b[39m\u001b[34m(artifact_path, loader_module, data_path, code_paths, infer_code_paths, conda_env, python_model, artifacts, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, prompts, name, params, tags, model_type, step, model_id)\u001b[39m\n\u001b[32m   3400\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3401\u001b[39m \u001b[33;03mLog a Pyfunc model with custom inference logic and optional data dependencies as an MLflow\u001b[39;00m\n\u001b[32m   3402\u001b[39m \u001b[33;03martifact for the current run.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3597\u001b[39m \u001b[33;03m    metadata of the logged model.\u001b[39;00m\n\u001b[32m   3598\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3599\u001b[39m flavor_name = _get_pyfunc_model_flavor_name(python_model)\n\u001b[32m-> \u001b[39m\u001b[32m3600\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mModel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3601\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3602\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3603\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3604\u001b[39m \u001b[43m    \u001b[49m\u001b[43mloader_module\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloader_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3605\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3606\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3608\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mregistered_model_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3611\u001b[39m \u001b[43m    \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3612\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_example\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3613\u001b[39m \u001b[43m    \u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43mawait_registration_for\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3615\u001b[39m \u001b[43m    \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3616\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3617\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3618\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3619\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3620\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresources\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3621\u001b[39m \u001b[43m    \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3622\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3623\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3624\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3625\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3626\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3627\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3628\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# only used for checking python model type\u001b[39;49;00m\n\u001b[32m   3629\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflavor_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflavor_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3630\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/models/model.py:1209\u001b[39m, in \u001b[36mModel.log\u001b[39m\u001b[34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, run_id, resources, auth_policy, prompts, name, model_type, params, tags, step, model_id, **kwargs)\u001b[39m\n\u001b[32m   1197\u001b[39m     prompts = [pr.uri \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pr, PromptVersion) \u001b[38;5;28;01melse\u001b[39;00m pr \u001b[38;5;28;01mfor\u001b[39;00m pr \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m   1199\u001b[39m mlflow_model = \u001b[38;5;28mcls\u001b[39m(\n\u001b[32m   1200\u001b[39m     artifact_path=model.artifact_location,\n\u001b[32m   1201\u001b[39m     model_uuid=model.model_id,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1207\u001b[39m     model_id=model.model_id,\n\u001b[32m   1208\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m \u001b[43mflavor\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[38;5;66;03m# `save_model` calls `load_model` to infer the model requirements, which may result\u001b[39;00m\n\u001b[32m   1211\u001b[39m \u001b[38;5;66;03m# in __pycache__ directories being created in the model directory.\u001b[39;00m\n\u001b[32m   1212\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m pycache \u001b[38;5;129;01min\u001b[39;00m Path(local_path).rglob(\u001b[33m\"\u001b[39m\u001b[33m__pycache__\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/tracing/provider.py:638\u001b[39m, in \u001b[36mtrace_disabled.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    636\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    637\u001b[39m         is_func_called = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m         result = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[38;5;66;03m# We should only catch the exception from disable() and enable()\u001b[39;00m\n\u001b[32m    640\u001b[39m \u001b[38;5;66;03m# and let other exceptions propagate.\u001b[39;00m\n\u001b[32m    641\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowTracingException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:3341\u001b[39m, in \u001b[36msave_model\u001b[39m\u001b[34m(path, loader_module, data_path, code_paths, infer_code_paths, conda_env, mlflow_model, python_model, artifacts, signature, input_example, pip_requirements, extra_pip_requirements, metadata, model_config, streamable, resources, auth_policy, **kwargs)\u001b[39m\n\u001b[32m   3327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _save_model_with_loader_module_and_data_path(\n\u001b[32m   3328\u001b[39m         path=path,\n\u001b[32m   3329\u001b[39m         loader_module=loader_module,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3338\u001b[39m         infer_code_paths=infer_code_paths,\n\u001b[32m   3339\u001b[39m     )\n\u001b[32m   3340\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m second_argument_set_specified:\n\u001b[32m-> \u001b[39m\u001b[32m3341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpyfunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_save_model_with_class_artifacts_params\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3343\u001b[39m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpython_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3345\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconda_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcode_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmlflow_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3350\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_pip_requirements\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3351\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3352\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_code_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_code_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3354\u001b[39m \u001b[43m        \u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m=\u001b[49m\u001b[43minfer_code_paths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3355\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/mlflow-genai/venv/lib/python3.11/site-packages/mlflow/pyfunc/model.py:1098\u001b[39m, in \u001b[36m_save_model_with_class_artifacts_params\u001b[39m\u001b[34m(path, python_model, signature, artifacts, conda_env, code_paths, mlflow_model, pip_requirements, extra_pip_requirements, model_config, streamable, model_code_path, infer_code_paths)\u001b[39m\n\u001b[32m   1094\u001b[39m         _maybe_compress_cloudpickle_dump(\n\u001b[32m   1095\u001b[39m             python_model, os.path.join(path, saved_python_model_subpath), compression\n\u001b[32m   1096\u001b[39m         )\n\u001b[32m   1097\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m1098\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[32m   1099\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFailed to serialize Python model. Please save the model into a python file \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1100\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mand use code-based logging method instead. See\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mhttps://mlflow.org/docs/latest/models.html#models-from-code for more information.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1104\u001b[39m     custom_model_config_kwargs[CONFIG_KEY_PYTHON_MODEL] = saved_python_model_subpath\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artifacts:\n",
      "\u001b[31mMlflowException\u001b[39m: Failed to serialize Python model. Please save the model into a python file and use code-based logging method instead. Seehttps://mlflow.org/docs/latest/models.html#models-from-code for more information."
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run: # Wrap llm as an MLflow model. \n",
    "    logged_model_info = mlflow.pyfunc.log_model( \n",
    "        artifact_path=\"model\", \n",
    "        python_model=GroqQAWrapper(), \n",
    "        input_example=pd.DataFrame( {\"question\": [\"What is agentic AI?\"]} ),\n",
    "        )\n",
    "    model_uri = f\"runs:/{run.info.run_id}/model\" \n",
    "    # Use predefined question-answering metrics to evaluate our model. \n",
    "    results = mlflow.evaluate( \n",
    "        model_uri, eval_data, targets=\"ground_truth\", \n",
    "        model_type=\"question-answering\", \n",
    "        extra_metrics=[ mlflow.metrics.toxicity(model=\"gemini/gemini-2.5-flash\"), \n",
    "                       mlflow.metrics.latency(model=\"gemini/gemini-2.5-flash\"), \n",
    "                       mlflow.metrics.genai.answer_similarity(model=\"gemini/gemini-2.5-flash\"), ], \n",
    "                       ) \n",
    "    print(f\"See aggregated evaluation results below: \\n{results.metrics}\") \n",
    "    eval_table = results.tables[\"eval_results_table\"] \n",
    "    df = pd.DataFrame(eval_table) \n",
    "    df.to_csv(\"eval.csv\", index=False) \n",
    "    print(\"Aggregated metrics:\") \n",
    "    print(eval_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
